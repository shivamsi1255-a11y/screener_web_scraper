# ğŸ” Screener.in Web Scraper

A beautiful and powerful web scraping application for **screener.in** built with Python and Streamlit. Extract stock screening data, preview it in real-time, and download it in CSV or JSON format with just a few clicks!

---

## âœ¨ Features

* **ğŸ”— URL Input**: Paste any screener.in URL
* **ğŸš€ One-Click Fetch**: Automatically scrapes all pages
* **ğŸ“Š Live Preview**: Interactive table preview
* **ğŸ“„ CSV Export**: Download data in CSV format
* **ğŸ“‹ JSON Export**: Download data in JSON format
* **ğŸ¨ Beautiful UI**: Modern, gradient-based design
* **âš¡ Fast & Efficient**: Automatic pagination handling
* **ğŸ›¡ï¸ Error Handling**: Robust validation and messages

---

## ğŸš€ Quick Start

### Option 1: Automated Setup (Recommended)

1. **Double-click** `setup.bat`

   * Creates a virtual environment
   * Installs all dependencies

2. **Double-click** `run_scraper.bat`

3. Open your browser at:

   ```
   http://localhost:8501
   ```

### Option 2: Manual Setup

```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run the scraper application
streamlit run scraper_app.py
```

---

## ğŸ“– How to Use

### Step 1: Enter URL

Paste a screener.in URL, for example:

```
https://www.screener.in/screens/2448025/sales-profit-20-eps-up/
```

### Step 2: Fetch Data

Click **ğŸš€ Fetch Data**. The app will:

* Fetch all pages
* Combine data
* Display total records

### Step 3: Preview Data

* Interactive table view
* Adjustable rows
* Column information

### Step 4: Download

* **ğŸ“„ CSV Download**
* **ğŸ“‹ JSON Download**

Files are auto-named with timestamps.

---

## ğŸ“ Project Structure

```
screener_scap/
â”‚
â”œâ”€â”€ scraper_app.py         # Main Streamlit application
â”œâ”€â”€ scraper.py             # Web scraping logic
â”œâ”€â”€ app.py                 # Neural network app (separate)
â”œâ”€â”€ neural_network.py      # Neural network implementation
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ .env                   # Environment configuration
â”œâ”€â”€ .gitignore             # Git ignore rules
â”œâ”€â”€ README.md              # Project documentation
â”œâ”€â”€ SCRAPER_README.md      # Scraper-specific documentation
â”œâ”€â”€ setup.bat              # Setup script
â”œâ”€â”€ run_scraper.bat        # Run scraper app
â””â”€â”€ run.bat                # Run neural network app
```

---

## ğŸ¯ Example URLs

* **Sales & Profit Growth (20% EPS Up)**

  ```
  https://www.screener.in/screens/2448025/sales-profit-20-eps-up/
  ```

* **High ROE Stocks**

  ```
  https://www.screener.in/screens/71064/high-roe/
  ```

* **Low Debt Companies**

  ```
  https://www.screener.in/screens/71063/low-debt/
  ```

---

## ğŸ”§ Technical Details

### Dependencies

```
streamlit==1.29.0
pandas==2.0.3
beautifulsoup4==4.12.2
lxml==4.9.3
html5lib==1.1
python-dotenv==1.0.0
```

### How It Works

1. Validates screener.in URL
2. Iterates through pages automatically
3. Extracts tables using `pandas.read_html()`
4. Cleans and merges data
5. Exports CSV or JSON

### Key Functions

* `fetch_screener_data(link)`
* `validate_screener_url(url)`
* `convert_to_csv(df)`
* `convert_to_json(df)`

---

## ğŸ¨ UI Highlights

* Gradient action buttons
* Responsive layout
* Live stats (rows & columns)
* Loading indicators
* Styled error/success messages

---

## âš™ï¸ Configuration

Edit `.env`:

```env
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=localhost
STREAMLIT_THEME_BASE=light
```

---

## ğŸ›¡ï¸ Error Handling

Handles:

* Empty or invalid URLs
* Network issues
* Parsing failures
* Export errors

---

## ğŸ“Š Data Formats

### CSV

```csv
S.No.,Name,CMP,P/E,Market Cap,Div Yld %,...
1,Company A,1234.5,25.3,50000,1.2,...
```

### JSON

```json
[
  {"S.No.": "1", "Name": "Company A", "CMP": "1234.5"}
]
```

---

## âš ï¸ Important Notes

1. 3-second delay between pages (rate limiting)
2. Respect screener.in Terms of Service
3. Intended for personal research
4. Verify data from official sources

---

## ğŸ”„ Future Improvements

* Custom delay settings
* Progress bar
* Data filters
* Excel export
* Scheduled scraping
* Data comparison

---

## ğŸ› Troubleshooting

| Issue         | Solution                          |
| ------------- | --------------------------------- |
| Import errors | `pip install -r requirements.txt` |
| Port in use   | Change port or free 8501          |
| Timeout       | Check internet                    |
| No data       | Verify URL                        |

Enable debug:

```env
LOG_LEVEL=DEBUG
```

---

## ğŸ“ License

MIT License

---

## ğŸ™ Acknowledgments

* Streamlit
* Pandas
* BeautifulSoup4
* Data source: Screener.in

---

## ğŸ¤ Contributing

Contributions welcome:

* Bug reports
* Feature requests
* Pull requests
* Documentation improvements

---

**Happy Scraping! ğŸš€**

Use responsibly and respect website terms.
